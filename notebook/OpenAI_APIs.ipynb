{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import urllib.request as ur\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from openai import OpenAI\n",
    "from IPython.display import IFrame, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65272af",
   "metadata": {},
   "source": [
    "<h3> Creating a client object to call the APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7fc6bc1d7220>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # or you can explicitly pass in the key (NOT RECOMMENDED)\n",
    "    api_key=os.getenv(\"OPENAI_KEY\"),\n",
    ")\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f27b5a",
   "metadata": {},
   "source": [
    "<h3> The GPT models: </h3>\n",
    "    \n",
    "Here is an example to call the completions API and check that the key is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d174f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a simple Python function that takes two numbers as input from the prompt and adds them together:\n",
      "\n",
      "```python\n",
      "def add_numbers_from_prompt():\n",
      "    num1 = float(input(\"Enter the first number: \"))\n",
      "    num2 = float(input(\"Enter the second number: \"))\n",
      "    result = num1 + num2\n",
      "    return result\n",
      "\n",
      "# Test the function\n",
      "print(\"The sum is:\", add_numbers_from_prompt())\n",
      "```\n",
      "\n",
      "When you run this code, it will prompt you to enter two numbers, and then it will calculate the sum and print the result.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "         \"content\": \"You are a skilled Python programmer.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a function that adds 2 numbers from the prompt.\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.model_dump()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598bb980",
   "metadata": {},
   "source": [
    "<h4>Getting information about the tokens consumption for this request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e82e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 115, 'prompt_tokens': 30, 'total_tokens': 145}\n"
     ]
    }
   ],
   "source": [
    "print(response.model_dump()['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0e183",
   "metadata": {},
   "source": [
    "You can compute the cost of each call using the `chat.compleations` API with the following formula: `((promt_tokens * <cost_of_input_tokens>) + (completion_tokens * <cost_of_output_tokens>)) / 1000`\n",
    "\n",
    "For instance, this request using  `gpt-3.5-turbo-1106` the cost is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe46586a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total cost for API call: $0.00026000000000000003 USD'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost_calculator_for_GPT_3_5_turbo(response):\n",
    "\n",
    "    # These 2 values are valid only for the \"gpt-3.5-turbo-1106\" model.\n",
    "    # Check https://openai.com/pricing for up-to-date prices\n",
    "    cost_of_input_tokens = 0.001\n",
    "    cost_of_output_tokens = 0.002\n",
    "\n",
    "    completion_tokens = response.model_dump()['usage']['completion_tokens']\n",
    "    prompt_tokens = response.model_dump()['usage']['prompt_tokens']\n",
    "\n",
    "    total_cost = (\n",
    "        (prompt_tokens * cost_of_input_tokens) + (completion_tokens * cost_of_output_tokens)\n",
    "    ) / 1000\n",
    "\n",
    "    return f\"Total cost for API call: ${total_cost} USD\"\n",
    "\n",
    "cost_calculator_for_GPT_3_5_turbo(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3899f9",
   "metadata": {},
   "source": [
    "<h4>Formatting the output generated from the API</h4>\n",
    "\n",
    "You can use `response_format` argument from the `chat.completions` API to structure the data generated by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080786c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost for API call: $0.000314 USD\n",
      "{\n",
      "  \"actor\": \"Tom Hanks\",\n",
      "  \"birthdate\": \"July 9, 1956\",\n",
      "  \"birthplace\": \"Concord, California, USA\",\n",
      "  \"nationality\": \"American\",\n",
      "  \"best_known_for\": \"Forrest Gump, Saving Private Ryan, Cast Away, and Toy Story\",\n",
      "  \"awards\": {\n",
      "    \"Academy Awards\": 2,\n",
      "    \"Golden Globe Awards\": 7,\n",
      "    \"Emmy Awards\": 1\n",
      "  },\n",
      "  \"marital_status\": \"Married\",\n",
      "  \"spouse\": \"Rita Wilson\",\n",
      "  \"children\": 4,\n",
      "  \"other_interests\": [\"directing\", \"producing\", \"writing\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you generate json with information from your favorite actor?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "print(cost_calculator_for_GPT_3_5_turbo(response))\n",
    "print(response.model_dump()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad0ab9",
   "metadata": {},
   "source": [
    "<h4>Mind the temeperature!</h4>\n",
    "\n",
    "You can use `temperature` to spice up the responses you get back from the models, but keep in mind that if you increase the `temperature` too much, things might not make much sense..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c232d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost for API call: $0.000124 USD\n",
      "{                     \n",
      "  \t\"firstName\": \"Leonardo\",\n",
      "\t    \"lastName\": \"DiCaprio\",\n",
      "\t    \"age\": 47,\n",
      "\t    \t  \"careerBegin\": 76956   \t               \n",
      "                         \n",
      "                    \n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "             \n",
      "  \t\t\t\t\t\t\t\t             \n",
      "                                                                                                                                                                                \n",
      "\t\n",
      "                                                                 \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you generate json with information from your favorite actor?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=1.9,\n",
    ")\n",
    "print(cost_calculator_for_GPT_3_5_turbo(response))\n",
    "print(response.model_dump()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7435f",
   "metadata": {},
   "source": [
    "<h4>Multiple answers and limiting tokens for the generated output</h4>\n",
    "\n",
    "You can use `n` argument to set the number of answers you want to get from the input prompt. While the `max_tokens` will limit the lenght of the answers generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9560b06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion_tokens': 60, 'prompt_tokens': 12, 'total_tokens': 72} \n",
      "\n",
      "Total cost for API call: $0.000132 USD \n",
      "\n",
      "Option 1: \n",
      "    \n",
      "    According to the International Astronomical Union's definition, Pluto is considered a dwarf planet rather than a\n",
      "\n",
      "    \n",
      "Option 2: \n",
      "    \n",
      "    The status of Pluto changed in 2006 when the International Astronomical Union (IAU)\n",
      "\n",
      "    \n",
      "Option 3: \n",
      "    \n",
      "    According to the International Astronomical Union, Pluto is classified as a \"dwarf planet.\" While\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Is Pluto a planet?\"}],\n",
    "    temperature=1.5,\n",
    "    n=3,\n",
    "    max_tokens=20,\n",
    ")\n",
    "\n",
    "print(response.model_dump()['usage'], '\\n')\n",
    "print(cost_calculator_for_GPT_3_5_turbo(response), '\\n')\n",
    "for i in response.model_dump()['choices']:\n",
    "    print(f\"\"\"Option {i['index'] + 1}:\n",
    "\n",
    "    {i['message']['content']}\n",
    "\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc118cfe",
   "metadata": {},
   "source": [
    "Note that for the previous example we set `n=3` and `max_tokens=20`, but the `completion_tokens` value was 60! \n",
    "\n",
    "This means that each one of the 3 outputs contains `20 tokens`, that is why the total amount of output tokens was 60. It is also worth note that even if each answer contains of 20 tokens, the strings that they represent have different lenghts.\n",
    "\n",
    "\n",
    "\n",
    "<h3>Embeddings</h3>\n",
    "\n",
    "Here you will see how to create embeddings for any string you send as `input` to the `ada 2` model.\n",
    "\n",
    "Note that the dimension of the embeddings is currently fixed to 1536 by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7867f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the vector: 1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.029523631557822227,\n",
       " 0.002989797852933407,\n",
       " -0.007745315786451101,\n",
       " -0.001285364618524909,\n",
       " 0.010958727449178696,\n",
       " 0.012396479956805706,\n",
       " 0.003584444522857666,\n",
       " -0.014231769368052483,\n",
       " -0.0057973917573690414,\n",
       " -0.03909098729491234]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=\"I am going to convert this into a vector!\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "embeddings = response.model_dump()['data'][0]['embedding']\n",
    "print(\"Dimension of the vector:\", len(embeddings))\n",
    "embeddings[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c9ff6",
   "metadata": {},
   "source": [
    "Following a classic example of word semantics being (more or less) preserved by the embeddings representing them, we can see how much of the relationships between the words is preserved through vector operations.\n",
    "\n",
    "For instance, using the set of words: `Queen`, `King`, `Woman` and `Man`, and by looking at their embeddings in 2D from the sample image below, one could think that the following operation should hold: `king + woman − man ≈ approx_queen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eff5e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"https://www.researchgate.net/profile/Peter-Sutor/publication/332679657/figure/fig1/AS:809485488640000@1570007788866/The-classical-king-woman-man-queen-example-of-neural-word-embeddings-in-2D-It.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f92cd27fcd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_img = (\n",
    "    \"https://www.researchgate.net/profile/Peter-Sutor/publication/\"\n",
    "    \"332679657/figure/fig1/AS:809485488640000@1570007788866/\"\n",
    "    \"The-classical-king-woman-man-queen-example-of-neural-word-embeddings-in-2D-It.png\"\n",
    ")\n",
    "IFrame(src=embedding_img, width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c876e0e",
   "metadata": {},
   "source": [
    "So, let us see if the embeddings generated by the `ada 2` model hold some of these relationships.\n",
    "\n",
    "First, we will compute the embeddings for each of this words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe75e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=\"Man\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "man_embedding = np.array(response.model_dump()['data'][0]['embedding'])\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"King\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "king_embedding = np.array(response.model_dump()['data'][0]['embedding'])\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"Woman\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "woman_embedding = np.array(response.model_dump()['data'][0]['embedding'])\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"Queen\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "queen_embedding = np.array(response.model_dump()['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae95de3",
   "metadata": {},
   "source": [
    "Once we have the embeddings for each word, we can proceed to compute the `approx_queen` embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ae475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_queen = king_embedding + woman_embedding - man_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5467df8",
   "metadata": {},
   "source": [
    "To see how close the `approx_queen` is to the `queen_embedding`, we can compute the `cosine similarity` of the 2 vectors with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f234082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e486551",
   "metadata": {},
   "source": [
    "Remember that the closer the value to 1 the more similar the vectors will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4c803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(queen_embedding, queen_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af9e80ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856166937644603"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(approx_queen, queen_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa81815d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6827180911100964"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(approx_queen, man_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91b5eb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8520945702663424"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(approx_queen, woman_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cb6b33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9175670437768388"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(approx_queen, king_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019935d3",
   "metadata": {},
   "source": [
    "So, after performing all the comparisons, we can see that the `approx_queen` embedding is closer to `king_embedding`, although it the is the most distant to the `man_embedding`.\n",
    "\n",
    "\n",
    "<h3> Images with the Dall-E models</h3>\n",
    "\n",
    "First, you will use the `dall-e-3` model to generate images from a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e9c47e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1024\"\n",
       "            height=\"1024\"\n",
       "            src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-XG5pIPuKqBP9LIvoY5L7L2AA/user-ayEVcXcZoz9I2E2DVITO1Cea/img-FN40vRrnCG52fJJRGVD5ibU5.png?st=2023-11-29T18%3A26%3A26Z&se=2023-11-29T20%3A26%3A26Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-29T19%3A07%3A37Z&ske=2023-11-30T19%3A07%3A37Z&sks=b&skv=2021-08-06&sig=Vx307l6ty4tqdkHBhlGg9%2BdNdsSpLkjtNgMEpIFp2oI%3D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc6bcac0fa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 1024\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"\"\"\n",
    "    Everything should be painted with the Van Gogh style.\n",
    "    A dinosaur playing guitar with flames in the background.\n",
    "    \"\"\",\n",
    "    size=f\"{image_size}x{image_size}\"\n",
    ")\n",
    "\n",
    "image_url = response.model_dump()['data'][0]['url']\n",
    "IFrame(src=image_url, width=image_size, height=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673376dd",
   "metadata": {},
   "source": [
    "<h4>Image edition</h4>\n",
    "\n",
    "\n",
    "The `edit` API lets you modify an `image` using a `mask` from the same image.\n",
    "\n",
    "For this part we will need to load a couple of images from the `resources` directory, so make sure to update the path accordingly to your setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "896df435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change this path to match your directory structure\n",
    "media_path = \"resources/\"\n",
    "\n",
    "chihuahua = open(media_path + \"chihuahua.png\", \"rb\")\n",
    "chihuahua_mask = open(media_path + \"chihuahua_mask.png\", \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a6661",
   "metadata": {},
   "source": [
    "Please note that only the transparent areas from the `mask` will be used for editing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3291fe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"256\"\n",
       "            height=\"256\"\n",
       "            src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-XG5pIPuKqBP9LIvoY5L7L2AA/user-ayEVcXcZoz9I2E2DVITO1Cea/img-3ZFz8lr2WUdbvCVZtf2mMQbt.png?st=2023-11-29T18%3A30%3A09Z&se=2023-11-29T20%3A30%3A09Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-29T19%3A09%3A12Z&ske=2023-11-30T19%3A09%3A12Z&sks=b&skv=2021-08-06&sig=RRU0AzHl%2BxiQ1MX0yMaKNv0AAygKUCVqF/DEN/I8etc%3D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc6bcac05e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 256\n",
    "\n",
    "response = client.images.edit(\n",
    "    image=chihuahua,\n",
    "    mask=chihuahua_mask,\n",
    "    prompt=\"\"\"\n",
    "    The chihuahua is on a trail in Hawaii with an active volcano in the background.\n",
    "    \"\"\",\n",
    "    n=1,\n",
    "    response_format='url',\n",
    "    size=f\"{image_size}x{image_size}\"\n",
    ")\n",
    "\n",
    "image_url = response.model_dump()['data'][0]['url']\n",
    "chihuahua_edit = ur.urlretrieve(image_url)[0]\n",
    "IFrame(src=image_url, width=image_size, height=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49abd67",
   "metadata": {},
   "source": [
    "You can see below the original `image` and the `mask` used in the `edit` call from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c01d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163bb971bc7540ffb0cd3dcacf010cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x08\\x02\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chihuahua.seek(0)\n",
    "chihuahua_mask.seek(0)\n",
    "\n",
    "img1=chihuahua.read()\n",
    "wi1 = widgets.Image(value=img1, format='jpg', width=image_size, height=image_size)\n",
    "img2=chihuahua_mask.read()\n",
    "wi2 = widgets.Image(value=img2, format='jpg', width=image_size, height=image_size)\n",
    "img3=open(chihuahua_edit, 'rb').read()\n",
    "wi3 = widgets.Image(value=img3, format='jpg', width=image_size, height=image_size)\n",
    "\n",
    "box=[wi1,wi2,wi3]\n",
    "chihuahuas=widgets.HBox(box)\n",
    "display(chihuahuas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fbce9",
   "metadata": {},
   "source": [
    "<h4>Image variation</h4>\n",
    "\n",
    "This will let you create a random variation of the original `image` provided to the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c971fc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"256\"\n",
       "            height=\"256\"\n",
       "            src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-XG5pIPuKqBP9LIvoY5L7L2AA/user-ayEVcXcZoz9I2E2DVITO1Cea/img-v0pfC8AloBHVeHOVtwd5SpmD.png?st=2023-11-29T18%3A30%3A43Z&se=2023-11-29T20%3A30%3A43Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-29T19%3A10%3A03Z&ske=2023-11-30T19%3A10%3A03Z&sks=b&skv=2021-08-06&sig=t2JpZjY8nc8RWMwUMwSgHFkPmybzrpC%2BJnTMlqj8194%3D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc6c18e5fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 256\n",
    "\n",
    "response = client.images.create_variation(\n",
    "    image=chihuahua,\n",
    "    n=1,\n",
    "    response_format='url',\n",
    "    size=f\"{image_size}x{image_size}\"\n",
    ")\n",
    "\n",
    "image_url = response.model_dump()['data'][0]['url']\n",
    "IFrame(src=image_url, width=image_size, height=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4477bfed",
   "metadata": {},
   "source": [
    "<h2>Audio with Whisper</h2>\n",
    "\n",
    "`whisper 1` will let you generate `transcriptions` from the audio files provided. By specifying the orignal language of the audio, you can help the model to get a faster and more accurate result!\n",
    "\n",
    "Make sure to check the limits for duration and file size in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beaab82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<audio controls><source src=resources/english_audio.mp3 type='audio/mpeg'></audio>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_audio_with_controls(file_path):\n",
    "    display(HTML(\"<audio controls><source src={} type='audio/mpeg'></audio>\".format(file_path)))\n",
    "\n",
    "english_audio_file_path = media_path + \"english_audio.mp3\"\n",
    "\n",
    "show_audio_with_controls(english_audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb47a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So, you're a travel agency that provides programs in Hajj and Umrah, and you're searching for the best hotels and services with extraordinary discounts. Well, look no further. Eid Hijri is giving travel agencies all over the world the opportunity to join its international alliance of agencies in Hajj and Umrah sectors.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=open(english_audio_file_path, \"rb\"),\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "transcript.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c0898",
   "metadata": {},
   "source": [
    "Note that this API also lets you play with the temperature, so you can see how much the transcription changes as you play with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96c321e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So, you're a travel pharmacy that serves as a дом 음식\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=open(english_audio_file_path, \"rb\"),\n",
    "    language=\"en\",\n",
    "    temperature=1.3,\n",
    ")\n",
    "transcript.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db37903",
   "metadata": {},
   "source": [
    "<h4>Translations</h4>\n",
    "\n",
    "This API will help you to generate `translations` from any language in the list of supported languages by Open AI, to a text in English.\n",
    "\n",
    "You can test it with the following audio in Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf72a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<audio controls><source src=resources/opiniones.mp3 type='audio/mpeg'></audio>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spanish_audio_file_path = media_path + \"opiniones.mp3\"\n",
    "\n",
    "show_audio_with_controls(spanish_audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77b3239d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love it, I like it very much, I like it, I don't like it, I don't like anything, I hate it I love them, I like them, I don't like them, I don't like anything, I hate\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file= open(spanish_audio_file_path, \"rb\")\n",
    "translation = client.audio.translations.create(\n",
    "  model=\"whisper-1\",\n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "translation.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1872e67",
   "metadata": {},
   "source": [
    "<h3>Text To Speech with TTS 1</h3>\n",
    "\n",
    "Pretty straightforward, type in whatever you want to say, choose the type of voice from the selection, point to the file where you want to store the audio and enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1858c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_speech_file = media_path + \"generated_speech.mp3\"\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Look mom, I am coding in Python!\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(output_speech_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f354ad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<audio controls><source src=resources/generated_speech.mp3 type='audio/mpeg'></audio>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_audio_with_controls(output_speech_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
